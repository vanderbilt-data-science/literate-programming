{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40-modeling-sklearn\n",
    "> Modeling using scikit-learn\n",
    "\n",
    "In this notebook, we train models using the pipeline functionality from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tables and visualizations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler\n",
    "from sklearn import config_context\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the following filename with the path of your data.\n",
    "data_filename = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and learn a bit\n",
    "df = pd.read_csv(data_filename)\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "Here, we employ the initial split to separate the training from the golden holdout test set.  We may split this in a prior notebook to standardize across modeling strategies.  Make sure to uncomment `class_column` below and fill in the name of the column of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_column = 'target_column'\n",
    "random_seed = 2435\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=class_column), df[class_column],\n",
    "                                                   test_size=0.25, random_state=random_seed, stratify=df[class_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure that everything seems OK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Train\n",
    "print('On X train: ')\n",
    "print('X train dimensions: ', X_train.shape)\n",
    "display(X_train.head())\n",
    "\n",
    "# X test\n",
    "print('\\nOn X test: ')\n",
    "print('X test dimensions: ', X_test.shape)\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Train\n",
    "print('On y train: ')\n",
    "print('y train dimensions: ', y_train.shape)\n",
    "display(y_train.head())\n",
    "\n",
    "# X test\n",
    "print('\\nOn y test: ')\n",
    "print('y test dimensions: ', y_test.shape)\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training pipeline\n",
    "The example below uses logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual pipelines for differing datatypes\n",
    "cat_pipeline = Pipeline(steps=[('cat_impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                               ('onehot_cat', OneHotEncoder(drop='if_binary'))])\n",
    "num_pipeline = Pipeline(steps=[('impute_num', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "                               ('scale_num', StandardScaler())])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish preprocessing pipeline by columns\n",
    "preproc = ColumnTransformer([('cat_pipe', cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "                             ('num_pipe', num_pipeline, make_column_selector(dtype_include=np.number))],\n",
    "                             remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the whole modeling pipeline with preprocessing\n",
    "pipe = Pipeline(steps=[('preproc', preproc),\n",
    "                       ('mdl', LogisticRegression(penalty='elasticnet', solver='saga', tol=0.01))])\n",
    "\n",
    "#visualization for steps\n",
    "with config_context(display='diagram'):\n",
    "    display(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_grid = {'mdl__l1_ratio' : np.linspace(0,1,5),\n",
    "               'mdl__C': np.logspace(-1, 6, 3) }\n",
    "grid_search = GridSearchCV(pipe, param_grid = tuning_grid, cv = 5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final fit\n",
    "The final fit may be present due to the grid search.  If so, you can use the best estimator functionality below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable importance\n",
    "Now we assess the importance in the selected model to reveal any potential insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip = grid_search.best_estimator_['mdl'].coef_[0]\n",
    "vip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get names in correct preproc order\n",
    "cat_names = grid_search.best_estimator_.named_steps['preproc'].transformers_[0][1].named_steps['onehot_cat'].get_feature_names()\n",
    "num_names = grid_search.best_estimator_.named_steps['preproc'].transformers_[1][2]\n",
    "\n",
    "#create df with vip info\n",
    "coef_info = pd.DataFrame({'feat_names':np.hstack([cat_names, num_names]), 'vip': vip})\n",
    "\n",
    "#get sign and magnitude information\n",
    "coef_info = coef_info.assign(coef_mag = abs(coef_info['vip']),\n",
    "                             coef_sign = np.sign(coef_info['vip']))\n",
    "\n",
    "#sort and plot\n",
    "coef_info = coef_info.set_index('feat_names').sort_values(by='coef_mag', ascending=False)\n",
    "sns.barplot(y=coef_info.index, x='coef_mag', hue='coef_sign', data=coef_info, orient='h', dodge=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
